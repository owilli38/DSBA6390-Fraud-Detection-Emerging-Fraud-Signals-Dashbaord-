{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owilli38/DSBA6390-Fraud-Detection-Emerging-Fraud-Signals-Dashbaord-/blob/main/DSBA6390_Fraud_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCNWW-7xJ9Ig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "So27UnLTkHfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set up Gemini API\n",
        "genai.configure(api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\")"
      ],
      "metadata": {
        "id": "I1FjXzGxkOm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash-lite')"
      ],
      "metadata": {
        "id": "lWxuaJqokvtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56j5eD7l_OC8",
        "outputId": "88319aff-60ff-432f-f3ea-e5e9cf5c1f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.12/dist-packages (0.14.14)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.14 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.14.14)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.6.18)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.14.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.46)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (9.1.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.17.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (2.17.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.7.1)\n",
            "Requirement already satisfied: pandas<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<7,>=6.1.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (6.7.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.26.2)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.14->llama_index) (26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (1.17.0)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://aistudio.google.com/usage?tab=rate-limit&timeRange=last-hour&project=gen-lang-client-0963402300"
      ],
      "metadata": {
        "id": "bN3935F1oPk5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13c1eb2e"
      },
      "source": [
        "## Ingest Data from Multiple Sources\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "369d65fc",
        "outputId": "78e985cf-e8e5-4a9e-d19f-be097b669c52"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the 'data' directory if it doesn't exist\n",
        "if not os.path.exists('./data'):\n",
        "    os.makedirs('./data')\n",
        "\n",
        "# Create a dummy text file inside the 'data' directory\n",
        "with open('./data/source1.txt', 'w') as f:\n",
        "    f.write(\"This is a dummy text file for source 1.\\nIt contains some sample content.\")\n",
        "\n",
        "print(\"Created 'data' directory and 'source1.txt' inside it.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 'data' directory and 'source1.txt' inside it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f119ae3c",
        "outputId": "44f2e09f-2f99-469a-9121-72041144710e"
      },
      "source": [
        "!pip install llama_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama_index in /usr/local/lib/python3.12/dist-packages (0.14.14)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.14 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.14.14)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.6.18)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama_index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.14.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.5.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.46)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (9.1.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.14->llama_index) (1.17.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (2.17.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.7.1)\n",
            "Requirement already satisfied: pandas<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<7,>=6.1.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (6.7.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama_index) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.26.2)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.14->llama_index) (26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (1.17.0)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.14->llama_index) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "000be516",
        "outputId": "b6861b52-b996-4fbc-8a7d-14b1762aceb3"
      },
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "# 1. Load documents from a local folder\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "# For now, we will just print the content of the first document to ensure it loaded correctly\n",
        "if documents:\n",
        "    print(\"Content of the first document:\")\n",
        "    print(documents[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4 document(s).\n",
            "Content of the first document:\n",
            "This is a dummy text file for source 1.\n",
            "It contains some sample content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62b460b",
        "outputId": "e1202cd1-8fcf-404e-c2e1-46fff0c19345"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Create dummy CSV file\n",
        "csv_data = {'column1': [1, 2, 3], 'column2': ['A', 'B', 'C']}\n",
        "df = pd.DataFrame(csv_data)\n",
        "df.to_csv('./data/source2.csv', index=False)\n",
        "\n",
        "# Create dummy JSON file\n",
        "json_data = {'id': 1, 'name': 'Item X', 'value': 100}\n",
        "with open('./data/source3.json', 'w') as f:\n",
        "    json.dump(json_data, f)\n",
        "\n",
        "# Create another dummy text file\n",
        "with open('./data/source4.txt', 'w') as f:\n",
        "    f.write(\"This is a dummy text file for source 4.\\nIt contains some more sample content.\")\n",
        "\n",
        "print(\"Created dummy files: source2.csv, source3.json, source4.txt inside 'data' directory.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dummy files: source2.csv, source3.json, source4.txt inside 'data' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98338e29",
        "outputId": "b39c8b2a-1bf8-4799-8660-a1395650064a"
      },
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# 1. Load documents from the local folder, which now contains four files\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "print(\"Content of all loaded documents:\")\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"--- Document {i+1} (file: {doc.metadata.get('file_name', 'N/A')}) ---\")\n",
        "    print(doc.text)\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 4 document(s).\n",
            "Content of all loaded documents:\n",
            "--- Document 1 (file: source1.txt) ---\n",
            "This is a dummy text file for source 1.\n",
            "It contains some sample content.\n",
            "\n",
            "\n",
            "--- Document 2 (file: source2.csv) ---\n",
            "1, A\n",
            "2, B\n",
            "3, C\n",
            "\n",
            "\n",
            "--- Document 3 (file: source3.json) ---\n",
            "{\"id\": 1, \"name\": \"Item X\", \"value\": 100}\n",
            "\n",
            "\n",
            "--- Document 4 (file: source4.txt) ---\n",
            "This is a dummy text file for source 4.\n",
            "It contains some more sample content.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "115b07e2"
      },
      "source": [
        "## Preprocess and Clean Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cdeb8b3",
        "outputId": "7c8de484-9bfe-49b1-ef7b-ef45c80d7b2b"
      },
      "source": [
        "import io\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Applies common text cleaning operations.\"\"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
        "    text = re.sub(r'[.,!?;:\"]', '', text)  # Remove common punctuation\n",
        "    return text\n",
        "\n",
        "\n",
        "# Iterate through documents and apply preprocessing\n",
        "for doc in documents:\n",
        "    file_name = doc.metadata.get('file_name', 'N/A')\n",
        "    current_doc_text = doc.text # Get the current text content\n",
        "\n",
        "    # Handle CSV files\n",
        "    if file_name.endswith('.csv'):\n",
        "        # Use io.StringIO to treat the text as a file\n",
        "        csv_string_io = io.StringIO(current_doc_text)\n",
        "        df = pd.read_csv(csv_string_io)\n",
        "\n",
        "        # Convert DataFrame to a descriptive string\n",
        "        processed_text = \"CSV Data:\\n\"\n",
        "        for index, row in df.iterrows():\n",
        "            row_description = \", \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
        "            processed_text += f\"Row {index + 1} has {row_description}.\\n\"\n",
        "        current_doc_text = processed_text.strip()\n",
        "\n",
        "    # Handle JSON files\n",
        "    elif file_name.endswith('.json'):\n",
        "        json_data = json.loads(current_doc_text)\n",
        "\n",
        "        # Convert dictionary to a descriptive string\n",
        "        processed_text = \"JSON record contains: \"\n",
        "        processed_text += \", \".join([f\"{k} is {v}\" for k, v in json_data.items()]) + \".\"\n",
        "        current_doc_text = processed_text\n",
        "\n",
        "    # Apply general text cleaning to the current document's text\n",
        "    cleaned_text = clean_text(current_doc_text)\n",
        "    # Update the document's content using set_content()\n",
        "    doc.set_content(cleaned_text)\n",
        "\n",
        "# Verify preprocessing steps\n",
        "print(\"--- Preprocessed Documents ---\")\n",
        "for i, doc in enumerate(documents):\n",
        "    file_name = doc.metadata.get('file_name', 'N/A')\n",
        "    print(f\"Document {i+1} (file: {file_name}):\")\n",
        "    print(doc.text[:200] + ('...' if len(doc.text) > 200 else ''))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preprocessed Documents ---\n",
            "Document 1 (file: source1.txt):\n",
            "this is a dummy text file for source 1 it contains some sample content\n",
            "\n",
            "\n",
            "Document 2 (file: source2.csv):\n",
            "csv data row 1 has 1 2 a b row 2 has 1 3 a c\n",
            "\n",
            "\n",
            "Document 3 (file: source3.json):\n",
            "json record contains id is 1 name is item x value is 100\n",
            "\n",
            "\n",
            "Document 4 (file: source4.txt):\n",
            "this is a dummy text file for source 4 it contains some more sample content\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7be30051"
      },
      "source": [
        "## Generate Vector Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73595e59",
        "outputId": "e1f39560-4144-416b-de24-264e1b7b488b"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install llama-index-embeddings-gemini\n",
        "\n",
        "from llama_index.embeddings.gemini import GeminiEmbedding\n",
        "import google.generativeai as genai\n",
        "\n",
        "api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\"\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "embed_model = GeminiEmbedding(api_key=api_key, model_name=\"models/text-embedding-004\")\n",
        "\n",
        "print(\"Gemini embedding model initialized with specified model name.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-embeddings-gemini in /usr/local/lib/python3.12/dist-packages (0.4.2)\n",
            "Requirement already satisfied: google-generativeai>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-gemini) (0.8.6)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-gemini) (0.14.14)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (2.189.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (2.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (5.29.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.5.2->llama-index-embeddings-gemini) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (1.27.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.14.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (4.5.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.0.46)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (9.1.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.12.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.1.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (1.72.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (4.9.1)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.26.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (4.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.16.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (3.3.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (26.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-embeddings-gemini) (0.6.2)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-gemini) (3.0.3)\n",
            "Gemini embedding model initialized with specified model name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2710397975.py:10: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/Support for this package will be discontinued as of v0.4.2) -- Deprecated since version 0.4.2.\n",
            "  embed_model = GeminiEmbedding(api_key=api_key, model_name=\"models/text-embedding-004\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "5b282224",
        "outputId": "8fa8b9b9-b03f-4eb6-fa5f-87988653e7cd"
      },
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Ensure the API key is configured\n",
        "api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\"\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "# List all models and filter for embedding models\n",
        "embedding_models = [m.name for m in genai.list_models() if \"embedContent\" in m.supported_generation_methods]\n",
        "\n",
        "if embedding_models:\n",
        "    print(\"Available embedding models that support embedContent:\")\n",
        "    for model_name in embedding_models:\n",
        "        print(f\"- {model_name}\")\n",
        "\n",
        "    # Choose the first available embedding model\n",
        "    chosen_model_name = embedding_models[0]\n",
        "    print(f\"\\nChoosing {chosen_model_name} for embedding.\")\n",
        "\n",
        "    from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
        "\n",
        "    # Initialize the embedding model with the chosen model name\n",
        "    embed_model = GoogleGenAIEmbedding(api_key=api_key, model_name=chosen_model_name)\n",
        "\n",
        "    print(\"Google Generative AI embedding model initialized with a valid model name.\")\n",
        "\n",
        "    # Generate embeddings for the cleaned text content\n",
        "    for doc in documents:\n",
        "        embedding_vector = embed_model.get_text_embedding(doc.text)\n",
        "        doc.embedding = embedding_vector\n",
        "\n",
        "    print(f\"Generated embeddings for {len(documents)} documents.\")\n",
        "\n",
        "    # Verify by printing the first few elements of the first document's embedding\n",
        "    if documents and documents[0].embedding is not None:\n",
        "        print(\"\\nFirst 5 elements of the first document's embedding:\")\n",
        "        print(documents[0].embedding[:5])\n",
        "    else:\n",
        "        print(\"No embeddings generated or documents list is empty.\")\n",
        "else:\n",
        "    print(\"No embedding models supporting 'embedContent' found.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available embedding models that support embedContent:\n",
            "- models/gemini-embedding-001\n",
            "\n",
            "Choosing models/gemini-embedding-001 for embedding.\n",
            "Google Generative AI embedding model initialized with a valid model name.\n",
            "Generated embeddings for 4 documents.\n",
            "\n",
            "First 5 elements of the first document's embedding:\n",
            "[-0.005121223, -0.007923673, 0.016410181, -0.0842078, -0.0067423484]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfd34853"
      },
      "source": [
        "## Index Embeddings for Vector Search\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8ab88c",
        "outputId": "bb4b7d4e-2ef8-4b5b-b606-199d2dca6b3f"
      },
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# Create an index from the documents, which now contain embeddings\n",
        "# Explicitly pass the embed_model to ensure it uses the Gemini embedding model\n",
        "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
        "\n",
        "print(\"VectorStoreIndex successfully created from documents using the specified embed_model.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorStoreIndex successfully created from documents using the specified embed_model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fbb05d0"
      },
      "source": [
        "## Implement Vector Similarity Search\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22f74d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9975e07b-fbde-4c57-f418-62589179c08d"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Re-run the previous code with the fix\n",
        "!{sys.executable} -m pip install llama-index-llms-google-genai\n",
        "\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "import google.generativeai as genai\n",
        "from llama_index.core import Settings\n",
        "\n",
        "api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\"\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "# Initialize the llama_index LLM wrapper for Google Generative AI\n",
        "# Using 'gemini-pro' as a commonly available generative model. If 'gemini-2.5-flash-lite' is preferred, it should be specified here if supported by the wrapper.\n",
        "llm_model = GoogleGenAI(api_key=api_key, model_name=\"gemini-pro\")\n",
        "\n",
        "# Set the LLM for the entire LlamaIndex application\n",
        "Settings.llm = llm_model\n",
        "\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# Define a sample query string\n",
        "sample_query = \"What is the content of the first source?\"\n",
        "\n",
        "try:\n",
        "    # Execute the query\n",
        "    response = query_engine.query(sample_query)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"Query:\", sample_query)\n",
        "    print(\"Response:\", response)\n",
        "except Exception as e:\n",
        "    if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "        print(f\"ClientError: Quota exceeded. Please wait a few moments and try again. Details: {e}\")\n",
        "    else:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: llama-index-llms-google-genai in /usr/local/lib/python3.12/dist-packages (0.8.7)\n",
            "Requirement already satisfied: google-genai<2,>=1.52.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (1.62.0)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (0.14.14)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (11.3.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (9.1.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (1.3.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.14.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.6.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (4.5.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (6.0.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.46)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (4.67.3)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.17.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (3.11)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.1.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.26.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (26.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.6.2)\n",
            "Requirement already satisfied: griffecli==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.0)\n",
            "Requirement already satisfied: griffelib==2.0.0 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (2.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffecli==2.0.0->griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.14.5->llama-index-llms-google-genai) (3.0.3)\n",
            "ClientError: Quota exceeded. Please wait a few moments and try again. Details: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 32.664243137s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbbc5b3f"
      },
      "source": [
        "## Develop ML Model for Ranking\n",
        "\n",
        "### Subtask:\n",
        "Build and train a machine learning model to rank the data. This will involve selecting relevant features from the ingested data, choosing an appropriate ML algorithm (e.g., regression, classification, or a ranking algorithm), and evaluating its performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1e01ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44043bbc-5086-448a-e5f8-906332dab0a0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract embeddings from the documents to use as features (X)\n",
        "X = np.array([doc.embedding for doc in documents])\n",
        "\n",
        "print(f\"Shape of feature matrix X: {X.shape}\")\n",
        "print(\"First 5 elements of the first document's embedding (feature vector):\")\n",
        "print(X[0][:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of feature matrix X: (4, 3072)\n",
            "First 5 elements of the first document's embedding (feature vector):\n",
            "[-0.00512122 -0.00792367  0.01641018 -0.0842078  -0.00674235]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b7d640d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8109cd16-d0ac-4c76-9677-644a6762651f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate importance scores (target variable y) for each document.\n",
        "# These are arbitrary values for demonstration purposes, ranging from 0 to 1.\n",
        "y = np.array([0.7, 0.9, 0.5, 0.8])  # Corresponding to source1.txt, source2.csv, source3.json, source4.txt\n",
        "\n",
        "print(f\"Shape of target vector y: {y.shape}\")\n",
        "print(\"Simulated importance scores (y):\")\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of target vector y: (4,)\n",
            "Simulated importance scores (y):\n",
            "[0.7 0.9 0.5 0.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51526026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19d9e3a-d81c-4f5c-b4a6-343d3f4d9e12"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Split data into training and testing sets (adjusting test_size to ensure at least two samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Regressor model\n",
        "rfr_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rfr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Random Forest Regressor Model Training and Evaluation:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"  R-squared (R2 Score): {r2:.4f}\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Model Training and Evaluation:\n",
            "  Mean Squared Error (MSE): 0.0569\n",
            "  Root Mean Squared Error (RMSE): 0.2386\n",
            "  R-squared (R2 Score): -21.7720\n",
            "  Mean Absolute Error (MAE): 0.2290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d170f61"
      },
      "source": [
        "## Develop ML Model for Severity Assessment\n",
        "\n",
        "### Subtask:\n",
        "Build and train a machine learning model to assess the severity of identified items. This model will likely be a classification model, categorizing items into different severity levels (e.g., low, medium, high).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57f8fc0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159a2595-51ac-4f19-a171-e40242c6599f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate severity labels (target variable y_severity) for each document.\n",
        "# These are arbitrary values for demonstration purposes:\n",
        "# 0: Low Severity, 1: Medium Severity, 2: High Severity\n",
        "y_severity = np.array([1, 2, 0, 1])  # Corresponding to source1.txt, source2.csv, source3.json, source4.txt\n",
        "\n",
        "print(f\"Shape of target vector y_severity: {y_severity.shape}\")\n",
        "print(\"Simulated severity labels (y_severity):\")\n",
        "print(y_severity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of target vector y_severity: (4,)\n",
            "Simulated severity labels (y_severity):\n",
            "[1 2 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc5967c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d39315-c202-4bbb-e71b-a139f438f053"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Using the feature matrix X (embeddings) and the simulated severity labels y_severity\n",
        "X_train_severity, X_test_severity, y_train_severity, y_test_severity = train_test_split(X, y_severity, test_size=0.5, random_state=42)\n",
        "\n",
        "# Instantiate a RandomForestClassifier model\n",
        "rf_classifier_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier_model.fit(X_train_severity, y_train_severity)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_severity_pred = rf_classifier_model.predict(X_test_severity)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_severity, y_severity_pred)\n",
        "precision = precision_score(y_test_severity, y_severity_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test_severity, y_severity_pred, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test_severity, y_severity_pred, average='macro', zero_division=0)\n",
        "\n",
        "print(\"Random Forest Classifier Model Training and Evaluation for Severity Assessment:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  Precision (Macro): {precision:.4f}\")\n",
        "print(f\"  Recall (Macro): {recall:.4f}\")\n",
        "print(f\"  F1-Score (Macro): {f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Model Training and Evaluation for Severity Assessment:\n",
            "  Accuracy: 0.5000\n",
            "  Precision (Macro): 0.2500\n",
            "  Recall (Macro): 0.5000\n",
            "  F1-Score (Macro): 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ad903a2"
      },
      "source": [
        "## Implement RAG for Summarization\n",
        "\n",
        "### Subtask:\n",
        "Integrate a Retrieval-Augmented Generation (RAG) system for summarizing information. This will involve retrieving relevant data chunks using vector search and then using a large language model to generate concise summaries based on the retrieved content.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cf90b9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d992f4-eedb-49bb-e84e-1f606beaee3a"
      },
      "source": [
        "import google.generativeai as genai\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# Ensure API key is configured (re-importing for clarity in this step)\n",
        "api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\"\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "# Ensure LLM is set for LlamaIndex (re-initializing if necessary, as it's a new cell context)\n",
        "# Use the model previously determined to be working for LLM queries\n",
        "llm_model = GoogleGenAI(api_key=api_key, model_name=\"gemini-pro\")\n",
        "Settings.llm = llm_model\n",
        "\n",
        "# Define a query string to ask for a summary of 'source1.txt'\n",
        "summary_query = \"Summarize the content of the first source. \"\n",
        "\n",
        "try:\n",
        "    # Execute the summarization query using the query engine\n",
        "    summary_response = query_engine.query(summary_query)\n",
        "\n",
        "    # Print the generated summary\n",
        "    print(\"Summarization Query:\", summary_query)\n",
        "    print(\"Generated Summary:\", summary_response)\n",
        "except Exception as e:\n",
        "    if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "        print(f\"ClientError: Quota exceeded. Please wait a few moments and try again. Details: {e}\")\n",
        "    else:\n",
        "        print(f\"An unexpected error occurred during summarization: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClientError: Quota exceeded. Please wait a few moments and try again. Details: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\nPlease retry in 24.435912049s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2429d69f"
      },
      "source": [
        "## Implement RAG for Evidence-Backed Fraud Signals\n",
        "\n",
        "### Subtask:\n",
        "Extend the RAG system to identify and generate evidence-backed fraud signals. This will involve prompting the language model to analyze retrieved information for patterns indicative of fraud and citing the specific data points as evidence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c92ec7e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1944432-70ad-4460-9bbb-b6a9c681351f"
      },
      "source": [
        "import google.generativeai as genai\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "# Ensure API key is configured (re-importing for clarity in this step)\n",
        "api_key = \"AIzaSyDWEDt1Jgm2AMno4vnArVhRq8jh03ZieZc\"\n",
        "genai.configure(api_key = api_key)\n",
        "\n",
        "# Ensure LLM is set for LlamaIndex (re-initializing if necessary, as it's a new cell context)\n",
        "# Use the model previously determined to be working for LLM queries\n",
        "llm_model = GoogleGenAI(api_key=api_key, model_name=\"gemini-pro\")\n",
        "Settings.llm = llm_model\n",
        "\n",
        "# Define a query string to elicit fraud signals and supporting evidence\n",
        "fraud_signal_query = \"Are there any fraud signals or unusual patterns in the documents, and what evidence supports them?\"\n",
        "\n",
        "try:\n",
        "    # Execute the fraud signal query using the query engine\n",
        "    fraud_response = query_engine.query(fraud_signal_query)\n",
        "\n",
        "    # Print the query and the generated response\n",
        "    print(\"Fraud Signal Query:\", fraud_signal_query)\n",
        "    print(\"Generated Fraud Signals and Evidence:\", fraud_response)\n",
        "except Exception as e:\n",
        "    if \"RESOURCE_EXHAUSTED\" in str(e):\n",
        "        print(f\"ClientError: Quota exceeded. Please wait a few moments and try again. Details: {e}\")\n",
        "    else:\n",
        "        print(f\"An unexpected error occurred during fraud signal detection: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClientError: Quota exceeded. Please wait a few moments and try again. Details: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 19.789670314s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8455bee"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review and integrate all components, providing a comprehensive overview of the solution, including data ingestion, embedding generation, vector search, ML models for ranking and severity, and RAG for summarization and fraud signal detection.\n"
      ]
    }
  ]
}